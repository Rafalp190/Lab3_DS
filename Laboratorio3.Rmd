---
title: "Laboratorio 3"
author: "Oliver Mazariegos, Rafael Leon y Alejandro Vasquez"
date: "19/09/2018"
output: 
  html_document:

    number_sections: false

    toc: true

    fig_width: 8

    fig_height: 6
    
    self_contained: true

    theme: cosmo

    highlight: tango

    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
#opts_knit$set(root.dir = "~/R")
library(data.table)
library(Rtsne)
library(ggplot2)
library(dplyr)
library(e1071)
library(caret)
library(reticulate)
train = as.data.table(read.csv(file = "data/train.csv"))

#library(reticulate)
use_python("c:/users/rafal/appdata/local/programs/python/python36")
```

# Analisis exploratorio

## Frecuencia de etiquetas

Veamos que etiquetas hay y cual es su frecuencia.

```{r cuantasLabels}
cuantasLabels = as.data.frame(table(train$label))
ggplot(data = cuantasLabels, aes(x = Var1, y = Freq, fill = Var1)) + geom_bar(stat="identity") + labs(x = "Etiqueta", y = "Frecuencia", fill = "Frecuencia")
```

## Rtsne

Debido a que hay 785 pixeles, redimencionaremos el conjunto de datos utilizando T-snea y veamos si se identifican grupos.

```{r RTsne}
set.seed(0)
tsneaOut = Rtsne(train[,c(2:785)])
redimension = as.data.frame(tsneaOut$Y)
ggplot(data = redimension, aes(x = V2, y = V1, col = as.factor(train$label))) + geom_point()
```

Efectivamente se puede notar que los datos se agrupan muy bien y en diez grupos distinos, lo cual es la cantidad de distintas clases. Esto significa que podriamos hacer una prediccion utilizando los pixeles de cada una de las imagenes o con la redimension de estos.


# Modelo de Redes Neuronales Simple
Se hizo un modelo secuencial de keras (libreria de Python), luego se "aplanan" (funcion "Flatten") los datos para modificar la dimensionalidad de los datos. Despues, se generaron 128 nodos con la funcion "Dense", utilizando el parametro "relu" que deciden las categorias a las que se clasificara cada dato. A este modelo, luego se le generaron 10 nuevos nodos con las categorias decididas anteriormente (hecho con "Dense"" y el parametro "softmax"). Por ?ltimo, el modelo fue compilado y ajustado a los datos, utilizando, primero 10 "epochs" (no presentados aqu?) y luego 5 "epochs".

```{python}

import numpy as np
import tensorflow as tf

from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.python.keras.utils import to_categorical
from tensorflow.python.keras.datasets import mnist
 

(training_data, training_labels), (testing_data, testing_labels) = mnist.load_data()
 
# 5. Preprocess input data
training_data = training_data.astype('float32')
testing_data = testing_data.astype('float32')
training_data /= 255
testing_data /= 255
 
# 6. Preprocess class labels
training_labels = to_categorical(training_labels, 10)
testing_labels = to_categorical(testing_labels, 10)
 
# 7. Define model architecture
model = Sequential()
 
model.add(Flatten(input_shape = (28, 28)))
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
 
# # 8. Compile model
model.compile(loss='categorical_crossentropy',
               optimizer='adam',
               metrics=['accuracy'])
 
# # 9. Fit model on training data
model.fit(training_data, training_labels, 
           batch_size=32, epochs=5, verbose=0)
 
# # 10. Evaluate model on test data
print("VALIDATE MODEL")
(loss, accuracy) =  model.evaluate(testing_data, testing_labels)
print('Test loss:', loss)
print('Test accuracy:', accuracy)
```

Con 10 "epochs" el modelo se ajusto un 98%. Para determinar si no se encontraba sobre ajustado, se volvio a correr con 5 "epochs". Con este cambio, el ajuste del modelo fue de 97.93%, por lo que se considera que el modelo predice adecuadamente los pixeles.


# Modelo de Deep Learning

Sea realizo un modelo de aprendizaje de maquina utilizando redes neuronales convolucionadas. Este se realizo en python utilizando tensorflow y keras.
```{python}
#Author Rafael Leon
#Example based onhttps://elitedatascience.com/keras-tutorial-deep-learning-in-python


import numpy as np
import tensorflow as tf

from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D
from tensorflow.python.keras.utils import to_categorical
from tensorflow.python.keras.datasets import mnist
 

(training_data, training_labels), (testing_data, testing_labels) = mnist.load_data()
 
# 5. Preprocess input data
training_data = training_data.reshape(60000, 1, 28, 28)
#print(training_data.shape)
testing_data = testing_data.reshape(10000, 1, 28, 28)
#print(testing_data.shape)
training_data = training_data.astype('float32')
testing_data = testing_data.astype('float32')
training_data /= 255
testing_data /= 255
 
# 6. Preprocess class labels
training_labels = to_categorical(training_labels, 10)
testing_labels = to_categorical(testing_labels, 10)
 
# 7. Define model architecture
model = Sequential()
 
model.add(Convolution2D(32, 1, 1, activation='relu', input_shape=(1,28,28)))
model.add(Convolution2D(32, 1, 1, activation='relu'))
model.add(MaxPooling2D(pool_size=(1,1)))
model.add(Dropout(0.25))
 
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))
 
# # 8. Compile model
model.compile(loss='categorical_crossentropy',
               optimizer='adam',
               metrics=['accuracy'])
 
# # 9. Fit model on training data
model.fit(training_data, training_labels, 
           batch_size=32, epochs=10, verbose=0)
 
# # 10. Evaluate model on test data
print("VALIDATE MODEL")
(loss, accuracy) =  model.evaluate(testing_data, testing_labels)
print('Test loss:', loss)
print('Test accuracy:', accuracy)
```

## Intepretacion de la precision del modelo
El modelo de Deep Learning Convolucional utiliza las capas del modelo de Redes Neuronales Simples y le agrega 3 capas convolucionales que reajustan el modelo antes de utilizar las redes simples. Esto incrementa la precision muy poco. Solamente un 0.007, Por lo que no hace mucha diferencia. Sin embargo es un mejor modelo ya que se le agregaron capas de Dropout, que evitan que se sobreajuste el modelo. 

# Algoritmos Convencionales

```{r trainTest}
porcentaje<-0.7
set.seed(09876984)
corte <- sample(nrow(redimension),nrow(redimension)*porcentaje) 
redimension = cbind(redimension, train$label)
colnames(redimension)[3] = "label"
redimension$label = as.factor(redimension$label)
trainSet<-redimension[corte,]
testSet<-redimension[-corte,]
```

## Support Vector Machine{.tabset .tabset-pills}

Support Vector Machines, (SVM) son un conjunto de algoritmos de aprendizaje supervisado desarrollados por Vladimir Vapnik y su equipo en los laboratorios AT&T.

Estos metodos estan propiamente relacionados con problemas de clasificacion y regresion.

Intentaremos clasificar con SVM la etiqueta de los sets de pixeles utilizando la redimension de Tsne.

### Lineal

```{r svm1}
set.seed(1)
model <- svm(label~. ,data=trainSet,kernel = "linear")
plot(model,trainSet, fill = trainSet$label)
prediccion <- predict(model,testSet)


cfmSVM<-confusionMatrix(as.factor(prediccion),as.factor(testSet$label))

cfmSVM
```

### Radial

```{r svm2}
set.seed(2)
model <- svm(label~. ,data=trainSet,kernel = "radial")
plot(model,trainSet, fill = trainSet$label)
prediccion <- predict(model,testSet)


cfmSVM<-confusionMatrix(as.factor(prediccion),as.factor(testSet$label))

cfmSVM
```

Gracias a la reduccion de dimensiones de Tsne se pudo utilizar support vector machine (SVM) con un kernel radial logrando un accuaracy del 96%. El kerner radial supero al kernel lineal ya que los grupos no pueden separarse por lineas o por patrones senoidales de una manera tan precisa, pero de forma radial si (recordemos del grafico de tsne que los grupos tenian formas de islas o cicunferencias). En el grafico de clasificacion del SVM se puede ver que los datos mal clasificados son los puntos de otra etiqueta/numero que caen sobre otro grupo.  

En la la matriz de confucion se puede ver que el `0` es la clase mas certera y en contraste el `9` tiene la menor certeza. Con la redimension de los pixeles, se puede ver que al menos un elemento de cada etiqueta/numero cae en la clasificacion de `8`. 

##Arbol de Decision

Los arboles de decision es un modelo de prediccion. Dado un conjunto de datos se fabrican diagramas de construcciones l?gicas, muy similares a los sistemas de predicci?n basados en reglas, que sirven para representar y categorizar una serie de condiciones que ocurren de forma sucesiva, para la resoluci?n de un problema.

En nuestro caso, imagenes de numeros, se espera que si cumple ciertas condiciones, las imagenes representan una etiqueta en especifico. Utilizaremos la matriz reducida por Tsne para hacer la clasificacion.

```{r DT}
library(rpart)
library(rpart.plot)
set.seed(0987)
dt_model<-rpart(label~.,trainSet,method = "class")
prp(dt_model,box.palette="Pu")

prediccion <- predict(dt_model, newdata = testSet)
columnaMasAlta<-apply(prediccion, 1, function(x) colnames(prediccion)[which.max(x)])
prediccion<-as.factor(columnaMasAlta)

#Matriz de confusion

cfmDT<-confusionMatrix(prediccion,testSet$label)
cfmDT

```

Con los arboles de decisiones se obtuvo una menor precision que con la SVM. Utilizando los arboles de decicion se obtuvo una certeza de 88%. Siendo el numero 8 y 7 los menos certeros para predecir. Esto puede ser devido a como toma las decisiones el algoritmo. El algoritmo de primero verifica la altura del punto (V1) y luego la posicion horizontal (V2) hasta poder clasificar cada uno de los puntos. En contraste, la SVM se vasa en areas y no en fronteras, lo que aporta a la precision del modelo.

# Comparacion de Algoritmos

* De los algoritmos de aprendizaje de maquina convencionales, el SVM (usando un kernel radial) es mas preciso que los arboles de decision.
* El algoritmo de Redes Neuronales simple es mas poderoso que los modelos tradicionales y no difiere mucho del modelo de redes neuronales convolucionadas
*El mejor modelo de los tres es el modelo de Redes Neuronales Convolucionadas.